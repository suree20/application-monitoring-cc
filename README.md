# Log Analytics System

This project is a distributed log analytics system that collects, processes, and visualizes logs from an API server. It uses **Kafka** for message streaming, **PostgreSQL** for data storage, and **Grafana** for real-time visualization.

---

## ğŸ“ Project Structure

- **API Server**: A Flask-based server with multiple endpoints for testing.
- **Workload Generator**: Simulates API requests and sends logs to Kafka.
- **Kafka Consumer**: Consumes logs from Kafka and stores them in PostgreSQL.
- **Database**: PostgreSQL database to store logs.
- **Grafana Dashboard**: Visualizes logs and metrics in real-time.

---

## âœ… Features

- Real-time log streaming and storage.
- Monitoring of API usage and performance.
- Visual dashboards for metrics and errors.
- Easily testable endpoints with workload simulation.

---

## ğŸ›  Prerequisites

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

---
## ğŸŒ Accessing Services
After the containers are up and running, you can access the services at:

- API Server: http://localhost:5000
- Grafana Dashboard: http://localhost:3000
Login with default credentials: admin / admin
---
## ğŸ“Š Grafana Dashboard
The Grafana dashboard provides real-time insights into the system. It includes:

- ğŸ“„ Real-time logs from API requests
- ğŸ“ˆ Requests per endpoint over time
- â± Response time trends
-â— Error rate percentage
-ğŸ“Š Request distribution by endpoint
---
## ğŸ§ª Testing the System
To verify that everything is working correctly:

1. Check if the API Server is running
curl http://localhost:5000/health

2. Check logs in PostgreSQL
docker exec -it <db-container-name> \
  psql -U postgres -d logsdb -c "SELECT * FROM logs;"
---
## ğŸ§¹ Cleanup
To stop and remove all containers:
docker-compose down

---
